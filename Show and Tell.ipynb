{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show and Tell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing the simplest model based on a [Show and Tell paper](https://arxiv.org/pdf/1411.4555.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = 'datasets'\n",
    "DATASET = 'mini_coco'\n",
    "ANNOTATIONS_PATH = 'annotations/captions_{0}2014.json'\n",
    "IMAGES_PATH = 'images/{0}2014'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import os\n",
    "\n",
    "train_dataset = torchvision.datasets.CocoCaptions(\n",
    "    root = os.path.join(ROOT, 'mini_coco', IMAGES_PATH.format('train')),\n",
    "    annFile = os.path.join(ROOT, 'mini_coco', ANNOTATIONS_PATH.format('train')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.Resize((200, 200)),\n",
    "     torchvision.transforms.ToTensor()])\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # WORKS ONLY FOR BATCH SIZE = 0!!!!!!\n",
    "    image = transform(batch[0][0])\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "\n",
    "    transformed_texts = []\n",
    "    for text in batch[0][1]:\n",
    "        transformed_texts.append(torch.tensor(transform_text(text)))\n",
    "    transformed_texts.sort(key=lambda x: x.shape[0], reverse=True)\n",
    "    \n",
    "    inputs = [text[:-1] for text in transformed_texts]\n",
    "    outputs = [text[1:] for text in transformed_texts]\n",
    "    \n",
    "    packed_inputs = torch.nn.utils.rnn.pack_sequence(inputs, enforce_sorted=True)\n",
    "    packed_outputs = torch.nn.utils.rnn.pack_sequence(outputs, enforce_sorted=True)\n",
    "    return image, packed_inputs, packed_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower()\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from collections import defaultdict\n",
    "\n",
    "c = defaultdict(int)\n",
    "\n",
    "for image, texts in cap:\n",
    "    for text in texts:\n",
    "        text = clean_text(text)\n",
    "        for word in text:\n",
    "            c[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_filtered = [word for word in c if c[word] > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = '<START>'\n",
    "UNK = '<UNK>'\n",
    "END = '<END>'\n",
    "\n",
    "c_filtered.append(START)\n",
    "c_filtered.append(UNK)\n",
    "c_filtered.append(END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2w = {}\n",
    "w2i = {}\n",
    "\n",
    "for index, word in enumerate(c_filtered):\n",
    "    i2w[index] = word\n",
    "    w2i[word] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(text):\n",
    "    text = clean_text(text)\n",
    "    \n",
    "    sequence = [w2i[START]]\n",
    "    for word in text:\n",
    "        if word in w2i:\n",
    "            sequence.append(w2i[word])\n",
    "        else:\n",
    "            sequence.append(w2i[UNK])\n",
    "    sequence.append(w2i[END])\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, dict_size, embedding_dim, hidden_size, *args, **kwargs):\n",
    "        super(SimpleModel, self).__init__(*args, **kwargs)\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3)\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(in_features=10580, out_features=hidden_size)\n",
    "        self.encoder_layers = [\n",
    "            self.conv1, self.pooling, self.relu,\n",
    "            self.conv2, self.pooling, self.relu,\n",
    "            self.conv3, self.pooling, self.relu]\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=dict_size, embedding_dim=embedding_dim)\n",
    "        self.rnn = nn.RNN(input_size=embedding_dim, hidden_size=hidden_size)\n",
    "        self.linear2 = nn.Linear(in_features=hidden_size, out_features=dict_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def encoder(self, image):\n",
    "        for layer in self.encoder_layers:\n",
    "            image = layer(image)\n",
    "        return self.linear1(image.view(-1, 10580))\n",
    "    \n",
    "    def decoder(self, image_vector, input_captions):\n",
    "        embeddings = nn.utils.rnn.PackedSequence(\n",
    "            self.embedding(input_captions.data),\n",
    "            input_captions.batch_sizes)\n",
    "        decoded, _ = self.rnn(embeddings, image_vector)\n",
    "        probs = self.softmax(self.linear2(decoded.data))\n",
    "        return nn.utils.rnn.PackedSequence(probs, decoded.batch_sizes)\n",
    "\n",
    "    def forward(self, image, input_captions):\n",
    "        image_vector = self.encoder(image).view(-1, self.hidden_size)\n",
    "        image_vector = image_vector.repeat(1, 5, 1)\n",
    "        return self.decoder(image_vector, input_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel(dict_size=len(w2i), embedding_dim=32, hidden_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10000):\n",
    "    running_loss = 0.0\n",
    "    for image, inputs, outputs in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ans = model(image, inputs)\n",
    "        loss = criterion(ans.data, outputs.data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    if epoch % 100 == 0:\n",
    "        print(running_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
